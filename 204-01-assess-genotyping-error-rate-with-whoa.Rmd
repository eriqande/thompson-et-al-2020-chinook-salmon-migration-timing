---
title: "Assess genotyping error rate via `whoa`"
author: "Eric C. Anderson"
date: "Last Updated: `r Sys.Date()`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
bibliography: references.bib
---

One of the referees was curious about how accurate (or inaccurate)
the process of imputation and phasing might have been on our relatively 
low coverage whole genome sequencing data. He was also curious about
what effect it might have on the trees that we inferred from the phased
haplotype data.  In this notebook we begin to address that issue by first estimating
the heterozygote miscall rate of our data amongst fall-run Chinook salmon
from the Sacramento-San Joaquin Basin. Heterozygote miscall, as a common
type of genotyping error in genotyping-by-sequencing data, was discussed in
@hendricksRecentAdvancesConservation2018, where there was also mention of software
for estimating heterozygote miscall rates, as a function of read depth,
via distortions from Hardy-Weinberg equilibrium. A method for doing
so is now distributed as the R package 'whoa' by Eric C. Anderson, available
from CRAN.

Here, our goal is to assess whether the imputed genotypes found amongst a large group
of fish from several largely undifferentiated populations (the fall and late-fall collections
from the Central Valley of California) are in proportions that indicate that there
has not been a gross under-identification of heterozygous individuals. 

Sacramento-San Joaquin Fall run Chinook salmon are largely undifferentiated between
different tributaries (and from the Late-Fall run) which makes them suitable for
consideration for use in 'whoa.'

This notebook will draw upon the intermediate files produced in 004.

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
start_time <- Sys.time()
```


```{r}
library(tidyverse)
library(vcfR)

# You must use a post-CRAN-release version of 'whoa'
# that deals with read depths of 0 (from fully imputed sites) appropriately.
# devtools::install_github("eriqande/whoa")
library(whoa)

dir.create("intermediates/204", showWarnings = FALSE, recursive = TRUE)
dir.create("outputs/204", showWarnings = FALSE, recursive = TRUE)
```


# First explore the raw gentoypes called by GATK

Since GATK seems to not include population frequency information to calculate
genotype posteriors (and, rather, appears to call genotypes based on the
maximum of the genotype likelihoods), we expect that our low-read depth
sequencing will yield raw genotypes from GATK that show evidence of
extreme deficits of heterozygotes.

```{sh}
# get names of the fall and late fall central valley fish:
bcftools query -l intermediates/004/almost-ready-for-imputation.vcf | \
  awk '/San_Joaquin_River_Fall/ || /Coleman_Hatchery_Late_Fall/ || Feather_River_Hatchery_Fall' \
  > intermediates/204/cv-fall-run-names.txt 

# pick out just the fall/late-fall from the CV
bcftools view -S intermediates/204/cv-fall-run-names.txt -Oz \
  intermediates/004/almost-ready-for-imputation.vcf > intermediates/204/fall-late-fall-raw-from-gatk-5.16Mb.vcf.gz
```

We investigate that with scatterplots of genotype frequencies observed and expected
under HWE in the 48 CV fall/late-fall fish:
```{r}
raw_gatk <- read.vcfR("intermediates/204/fall-late-fall-raw-from-gatk-5.16Mb.vcf.gz")

raw_freqs <- exp_and_obs_geno_freqs(raw_gatk)

geno_freqs_scatter(raw_freqs, alpha = 0.04, max_plot_loci = 1e15)
```

Indeed.  As expected, the raw genotype calls from GATK show substantial departures
from HWE in a collection of from fish which it is to be expected.


# Get the VCF of imputed/phased haplotypes from 004 and add depths to it

Here we test for an improvement in genotype proportions after imputation of
genotypes from genotype likelihoods, and using haplotype information and linkage
disequilibrium 

```{sh}
cp intermediates/004/almost-ready-for-imputation.vcf intermediates/204
bgzip -f intermediates/204/almost-ready-for-imputation.vcf
bcftools index intermediates/204/almost-ready-for-imputation.vcf.gz


# reattach the DP information
bcftools annotate -a  intermediates/204/almost-ready-for-imputation.vcf.gz -c FMT/DP \
  -Oz -o intermediates/204/imputed-all-fish-with-DP.vcf.gz intermediates/004/greb1l-imp-phased.vcf.gz

# pick out just the fall/late-fall from the CV
bcftools view -S intermediates/204/cv-fall-run-names.txt -Oz \
  intermediates/204/imputed-all-fish-with-DP.vcf.gz > intermediates/204/fall-late-fall-imp-and-phased-5.16Mb.vcf.gz

```

# Now, run it through `whoa`

First read it in and make a geno_freq scatter of it:
```{r}
v <- read.vcfR("intermediates/204/fall-late-fall-imp-and-phased-5.16Mb.vcf.gz")

gfreqs <- exp_and_obs_geno_freqs(v)

geno_freqs_scatter(gfreqs, alpha = 0.04, max_plot_loci = 1e15)
```

That is a considerable improvement.  We can conclude from this that, at a gross level,
the imputation from BEAGLE is working reasonably well, despite the fact that fish from
multiple populations were included together in the BEAGLE imputation analysis.

Now, try to infer an overall het miscall rate:
```{r}
overall <- infer_m(v, minBin = 1e15)
```
Look at the posterior mean estimate:
```{r}
overall$m_posteriors
```

So, a het miscall rate of a little greater than 5%.  That is quite low.  Note that a more
suitable name for this quantity might be the "heterozygote distortion rate," since it indicates
that there is a distortion of the heterozygote genotype frequencies that is consistent with
heterozygotes being incorrectly called as homozygotes at a rate of 5%; however, the actual rate
at which heterozygotes are called as homozygotes may be higher than this (as will be seen
in the next analysis, 204-02).

Let's look at the MCMC trace:
```{r}
ggplot(overall$m_traces, aes(x = sweep, y = value)) +
  geom_line()
```
That shows good mixing.

Now, let's see if we can break things down by different read depth bins:
```{r}
binned <- infer_m(v, minBin = 2e04)
```
Check out the posterior means:
```{r}
binned$m_posteriors
```

Let's plot the traces:
```{r}
binned$m_traces %>%
  left_join(binned$m_posteriors %>% select(bin, mean_dp)) %>%
  ggplot(., aes(x = sweep, y = value)) +
  geom_line() +
  facet_wrap(~ as.factor(mean_dp))
```

So, that shows what we expect: that heterozygotes appear to be miscalled as homozygotes
at a higher rate when the read depth is low.  This is exactly what we expect.

Note that these are error estimates for sites across the whole 5.16 Mb.  We might expect
the imputation and the phasing to be more accurate in areas with high LD, such as what we find 
in the RoSA.  

## Effective rate of genotyping errors

Also, those esimated heterozygote miscall rates are the rates at which heterozygotes are miscalled
as homozygotes (the most common type of genotyping error with these sorts of data).  However,
only a fraction of the sites are heterozygous.  So, what does
that translate to for these fish in terms of average rate of genotyping error?  Well it depends on the
allele frequencies. Let's do a quick calculation:
```{r}
vt <- vcfR2tidy(v)$gt %>%
  mutate(DP = ifelse(is.na(gt_DP), 0, gt_DP)) %>%
  select(-gt_DS, -gt_GP, -gt_DP, -gt_GT_alleles)

dpjoins <- binned$m_posteriors %>%
  mutate(DP = as.integer(mean_dp)) %>%
  select(DP, mean) %>%
  rename(est_hmr = mean)

vt_with_hmr <- vt %>%
  left_join(dpjoins, by = "DP") %>%
  mutate(est_hmr = ifelse(is.na(est_hmr), 0.00138, est_hmr)) # if DP > 5 just say het miscall rate is 0.00138

vt_with_hmr %>%
  separate(gt_GT, into = c("a", "b"), convert = TRUE, sep = "\\|") %>%
  gather(key = "gene_copy", value = "allele", a, b) %>%
  group_by(POS) %>%
  mutate(
    n1 = sum(allele == 1),
    n0 = sum(allele == 0)
  ) %>%
  mutate(het_freq = 2 * n1 / (n0 + n1) * n0 / (n0 + n1)) %>%
  mutate(exp_geno_rate = het_freq * est_hmr) %>%
  ungroup() %>%
  summarise(mean_est_geno_err_rate = mean(exp_geno_rate))
```

So, if we use the rate of heterozygote miscalls estimated here from
distortions from HWE, and we only count heterozygote miscalls, we get a rate
of about 1.3% of all genotypes being incorrect.
That is not a high fraction of all genotypes that are expected to be incorrect.

However, a more definitive comparison would involve comparing
the imputed genotypes of high-read depth individuals to the imputed genotypes
from those same individuals after subsampling the reads from them to a lower
read depth, like 1.5.  This is done in the next notebook (204-02)



# Session Info

```{r}
sessioninfo::session_info()
```

# Running Time

Running the code and rendering this notebook required approximately this much time
on a Mac laptop of middling speed:
```{r}
Sys.time() - start_time
```

# Citations



